{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TKlOXVFpJj7q"
      ],
      "mount_file_id": "1IusbnnzHn-29ujpoFiKIqmZPqLPK4mpQ",
      "authorship_tag": "ABX9TyOEVM2GOS7hKV9OPspm6hhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajima-yasutoshi/DataMinig/blob/main/20231213/%E5%88%86%E9%A1%9E2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データマイニング第12回（2023/12/13）"
      ],
      "metadata": {
        "id": "g8YJ3oojiqNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#本日の講義の目的\n",
        "\n",
        "機械学習の準備として、\n",
        "ロジスティック回帰を例にして、予測精度を向上させるテクニックに関して\n",
        "詳しく説明を行う。\n",
        "\n",
        "1. 説明変数にカテゴリ変数を用いる\n",
        "\n",
        "1. ハイパーパラメータチューニング\n"
      ],
      "metadata": {
        "id": "wUezl4MyB_v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n"
      ],
      "metadata": {
        "id": "8zFBC9q961jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install japanize-matplotlib"
      ],
      "metadata": {
        "id": "g9TNYrU66eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリーのインポート"
      ],
      "metadata": {
        "id": "ZcX_E1F-64Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "n433p8b8cp6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 分類（ロジスティック回帰）に必要なライブラリー\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# その他必要なライブラリー\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "yyL6VVt3KRLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 【参考】ロジスティック回帰ライブラリー\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ],
      "metadata": {
        "id": "Kag2HqlpNLtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic データを使った例\n"
      ],
      "metadata": {
        "id": "TKlOXVFpJj7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを読み込む\n",
        "# 変数名を data とした\n",
        "data = sns.load_dataset(\"titanic\") #タイタニックのデータ\n",
        "data.info()\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "j_M6pfGUdT3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの説明\n",
        "\n",
        "列名 | 型 | 意味\n",
        "---  | --- | --\n",
        "survived\t| カテゴリ | 生存フラグ（0=死亡、1=生存）\n",
        "pclass\t|  カテゴリ |チケットクラス（1stクラス、2ndクラス、3rdクラス）\n",
        "sex\t|  カテゴリ |性別（male=男性、female＝女性）\n",
        "sge\t|  数値 |年齢\n",
        "sibsp\t|  数値 |タイタニックに同乗している兄弟/配偶者の数\n",
        "parch\t|  数値 |タイタニックに同乗している親/子供の数\n",
        "fare\t|  数値 |料金\n",
        "embarked\t|  カテゴリ |出港地（タイタニックへ乗った港）(C=Cherbourg、Q=Queenstown、S=Southampton)\n",
        "class |  カテゴリ |乗船クラス\n",
        "who | カテゴリ |男性 or 女性\n",
        "adult_male |  カテゴリ |成人男性であるかどうか\n",
        "deck |  カテゴリ |乗船していたデッキ\n",
        "embark_town |  カテゴリ |出港地\n",
        "alive |  カテゴリ |生存したかどうか\n",
        "alone |  カテゴリ |一人であったかどうか"
      ],
      "metadata": {
        "id": "t7UJupBadfY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理\n",
        "\n",
        "このデータには欠損値が含まれているため、前処理を行う。"
      ],
      "metadata": {
        "id": "sxvvu9emqE2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 欠損値を確認する\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "3mFcWAqQd0qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# age, embarked deck の欠損値を埋める\n",
        "\n",
        "# 平均値で欠損値を埋める。\n",
        "data['age'].fillna(data['age'].mean(), inplace=True)\n",
        "\n",
        "# 最頻値で欠損値を埋める。\n",
        "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
        "data['embark_town'].fillna(data['embark_town'].mode()[0], inplace=True)\n",
        "\n",
        "# 結果を確認\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "_jzkQkrvd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基礎集計"
      ],
      "metadata": {
        "id": "YzV1YdeoqSYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 基本的な統計情報を表示\n",
        "print(data.describe())\n",
        "\n",
        "# 生存者数と死亡者数を集計\n",
        "survived_counts = data['survived'].value_counts()\n",
        "print(\"\\n生存者数と死亡者数の集計:\")\n",
        "print(survived_counts)\n",
        "\n",
        "# 乗客のクラスごとの生存率を計算\n",
        "survival_rate_by_class = data.groupby('pclass')['survived'].mean()\n",
        "print(\"\\nクラスごとの生存率:\")\n",
        "print(survival_rate_by_class)\n",
        "\n",
        "# 性別ごとの生存率を計算\n",
        "survival_rate_by_gender = data.groupby('sex')['survived'].mean()\n",
        "print(\"\\n性別ごとの生存率:\")\n",
        "print(survival_rate_by_gender)\n",
        "\n",
        "# 年齢の分布を表示\n",
        "print(\"\\n年齢の分布:\")\n",
        "print(data['age'].hist())"
      ],
      "metadata": {
        "id": "vQPkr1kMdog4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ロジスティック回帰モデルの構築"
      ],
      "metadata": {
        "id": "ceIrckdNnYgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、数値型の項目のみでモデルを作成し精度を確認する。"
      ],
      "metadata": {
        "id": "BuKY6xQ8ndgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 説明変数と目的変数を選択\n",
        "# 数値データのみで予測\n",
        "X = data[[ 'age', 'fare', 'sibsp', 'parch']]\n",
        "y = data[['survived']]"
      ],
      "metadata": {
        "id": "ulgIt8EvebAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを学習用と検証用に分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 準備のための手順\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 標準化後のものは別の変数にセットすると良い\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# ロジスティック回帰モデルを作成\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルを訓練\n",
        "model.fit(X_train_scaled, y_train.values.ravel()  )\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# 回帰係数を可視化\n",
        "sns.barplot(x=model.coef_[0], y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q1GBsffU5UGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリ変数をOne Hot Encoding\n",
        "data_encoded = pd.get_dummies(data[['embarked', 'class', 'who', 'adult_male', 'alone']], drop_first=True)\n",
        "\n",
        "# 説明変数と目的変数を設定\n",
        "X = pd.concat([data[['age', 'fare', 'sibsp', 'parch']], data_encoded], axis=1)\n",
        "y = data['survived']"
      ],
      "metadata": {
        "id": "OzUk33bJn2j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 準備のための手順\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 標準化後のものは別の変数にセットすると良い\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# ロジスティック回帰モデルを作成\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルを訓練\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# 特徴量の重要度を可視化\n",
        "sns.barplot(x=model.coef_[0], y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7q1cK6gYe_LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング"
      ],
      "metadata": {
        "id": "ZjFF5JlDMVbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正則化パラメータ\n",
        "\n",
        "ロジスティック回帰には、「正則化パラメータ」があり、\n",
        "例えば、以下のように指定する。\n",
        "\n",
        "```\n",
        "model = LogisticRegression(C=1.0)\n",
        "```\n",
        "\n",
        "1.0の部分を変更することで精度をより向上させることが可能である。\n",
        "なお、今までは指定を省略していたが、デフォルトとして C=1.0 が指定されていた。\n",
        "\n",
        "\n",
        "正則化パラメータとして、どの値が適切かを調べるためには、\n",
        "**グリッドサーチ**が用いられる。\n",
        "\n",
        "そのためには、正則化パラメータの候補を以下のように設定する。\n",
        "\n",
        "```\n",
        "param_grid = {'C': [ 0.1, 0.15, 0.2, 0.3, 1, 2]}\n",
        "```\n",
        "\n",
        "正則化パラメータは正の値で、多くの場合は 0.1 ～ 100の範囲を候補とする。\n",
        "\n",
        "\n",
        "候補を設定したら、GridSearchCV を設定し、fitで実行する。\n",
        "\n",
        "```\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train.values.ravel() )\n",
        "```\n",
        "\n",
        "実行した結果、最適なモデルを以下のように得ることができる。\n",
        "```\n",
        "best_model = grid_search.best_estimator_\n",
        "```"
      ],
      "metadata": {
        "id": "tgp-VQa-7uy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインポート\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# パラメータグリッドを設定\n",
        "param_grid = {'C': [ 0.1, 0.15, 0.2, 0.3, 1, 2]}\n",
        "\n",
        "# GridSearchCVを設定\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "\n",
        "# グリッドサーチを実行\n",
        "grid_search.fit(X_train_scaled, y_train.values.ravel() )\n",
        "\n",
        "# 最適なパラメータとスコアを出力\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "# print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
        "\n",
        "# 最適なパラメータでテストデータを評価\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_train_scaled)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Validation set accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "n6sbG3umqaqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 精度が向上する様子をグラフで示す\n",
        "scores = grid_search.cv_results_['mean_test_score']\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=param_grid['C'], y=scores)\n",
        "plt.xlabel('C (Inverse of regularization strength)')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('Optimizing l2 Penalty with Grid Search')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M2kdwcnChhPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "eb2GYJAz5z_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# その他の参考となるサイト\n",
        "https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
        "\n"
      ],
      "metadata": {
        "id": "XZNhEBfLmwHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset\n"
      ],
      "metadata": {
        "id": "o6Hnl0G417rb"
      }
    }
  ]
}